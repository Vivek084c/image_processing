{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image as im\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mattmdjaga/human_parsing_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list=[]\n",
    "mask_list=[]\n",
    "for i in range(10000):\n",
    "    img_list.append(dataset[\"train\"][i][\"image\"])\n",
    "    mask_list.append(dataset[\"train\"][i][\"mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10000):\n",
    "#     mask_list[i].save(f\"dataset\\\\train\\\\Categories\\\\img_{i}.png\")\n",
    "l=os.listdir(\"dataset\\\\train\\\\Categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating rgb mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting mask to rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grayscale_to_rgb_mask(image,classes,rgb_color_map):\n",
    "#     image=np.expand_dims(image,axis=-1)\n",
    "#     h, w, _=image.shape\n",
    "#     image=image.astype(np.int32)\n",
    "\n",
    "#     output=[]\n",
    "#     for i,pixcel in enumerate(image.flatten()):\n",
    "#         output.append(rgb_color_map[pixcel])\n",
    "#     output=np.reshape(output, (h,w,3))\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 400, 1)\n"
     ]
    }
   ],
   "source": [
    "# a1=np.array(mask_list[0])\n",
    "# a1=np.expand_dims(a1,axis=-1)\n",
    "# print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5000,10000):\n",
    "#     output=grayscale_to_rgb_mask(np.array(mask_list[i]),classes, rgb_color_map )\n",
    "#     cv2.imwrite(f\"img_{i}.jpg\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def get_array_mask(num,arr):\n",
    "    mask_array=arr[240000*num:(240000*num)+240000].reshape(600,400)\n",
    "    return mask_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #saving the mask_list in np array \n",
    "# save_array=np.array(mask_list[0]).flatten()\n",
    "# for i in range(1,500):\n",
    "#     save_array=np.append(save_array,np.array(mask_list[i]).flatten())\n",
    "#     print(i)\n",
    "# np.save(\"mask_array\",save_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "label_map={\"0\": \"Background\", \"1\": \"Hat\", \"2\": \"Hair\", \"3\": \"Sunglasses\", \"4\": \"Upper-clothes\", \"5\": \"Skirt\", \"6\": \"Pants\", \"7\": \"Dress\", \"8\": \"Belt\", \"9\": \"Left-shoe\", \"10\": \"Right-shoe\", \"11\": \"Face\", \"12\": \"Left-leg\", \"13\": \"Right-leg\", \"14\": \"Left-arm\", \"15\": \"Right-arm\", \"16\": \"Bag\", \"17\": \"Scarf\"}\n",
    "rgb_color_map=[[0,0,0], [0,0,128], [0,0,255], [0,85,0], [51,0,170], [0,85,255], [85,0,0], [221,119,0], [0,85,85], [85,85,0], [0,51,85], [128,86,52], [0,28,0], [255,0,0], [221,170,51], [225,225,0], [170,255,85], [85,255,170]]\n",
    "classes=[\"Background\",  \"Hat\",  \"Hair\",  \"Sunglasses\",  \"Upper-clothes\", \"Skirt\", \"Pants\",  \"Dress\", \"Belt\",  \"Left-shoe\", \"Right-shoe\", \"Face\", \"Left-leg\", \"Right-leg\", \"Left-arm\", \"Right-arm\", \"Bag\", \"Scarf\"]\n",
    "\n",
    "COLOR_MAP=[k for k in range(18)]\n",
    "\n",
    "create_path(\"dataset\\\\train\\\\input\")\n",
    "create_path(\"dataset\\\\train\\\\Categories\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT=600\n",
    "IMAGE_WIDTH=400\n",
    "NUM_CLASSES=18\n",
    "INPUT_SHAPE=(IMAGE_HEIGHT,IMAGE_WIDTH,3)\n",
    "BATCH_SIZE=8\n",
    "NUM_EPOCH=100\n",
    "LR=1e-4\n",
    "\n",
    "#dataset paths\n",
    "dataset_path=\"dataset\\\\train\"\n",
    "model_path=os.path.join(\"files\",\"model.h5\")\n",
    "csv_path=os.path.join(\"files\",\"data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(path,split=0.2):\n",
    "    #loading the images\n",
    "    train_x=sorted(glob(os.path.join(path, \"input\", \"*\")))\n",
    "    train_y=sorted(glob(os.path.join(path, \"Categories\", \"*\")))\n",
    "\n",
    "    split_size = int(split * len(train_x))\n",
    "\n",
    "    train_x, valid_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(train_y, test_size=split_size, random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y) \n",
    "\n",
    "\n",
    "(train_x,train_y), (test_x, test_y), (valid_x, valid_y)=load_dataset(dataset_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# color map processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colormap():\n",
    "    colormap=[k for k in range(18)]\n",
    "    classmap=[\n",
    "        \"Background\",\n",
    "        \"Hat\",\n",
    "        \"Hair\",\n",
    "        \"Sunglasses\",\n",
    "        \"Upper-clothes\",\n",
    "        \"Skirt\",\n",
    "        \"Pants\",\n",
    "        \"Dress\",\n",
    "        \"Belt\",\n",
    "        \"Left-shoe\",\n",
    "        \"Right-shoe\",\n",
    "        \"Face\",\n",
    "        \"Left-leg\",\n",
    "        \"Right-leg\",\n",
    "        \"Left-arm\",\n",
    "        \"Right-arm\",\n",
    "        \"Bag\",\n",
    "        \"Scarf\"\n",
    "    ]\n",
    "    return classmap, colormap\n",
    "\n",
    "CLASSES, COLORMAP=get_colormap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    cv2.imwrite(\"testimg.jpg\",x)\n",
    "    x = x / 255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mask(path):\n",
    "    x=cv2.imread(path,cv2.IMREAD_ANYDEPTH)\n",
    "    output=[]\n",
    "    for color in COLORMAP:\n",
    "        cmap=np.equal(x, color)\n",
    "        output.append(cmap)\n",
    "    output=np.stack(output, axis=-1)\n",
    "    output=output.astype(np.uint8)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\\train\\input\\img_8728.jpg\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    \"\"\"x and y represent image path and mask path\"\"\"\n",
    "    def f(x,y):\n",
    "        x=x.decode()\n",
    "        y=y.decode()\n",
    "        x=read_img(x)\n",
    "        y=read_mask(y)\n",
    "        return x,y\n",
    "    image,mask=tf.numpy_function(f, [x, y],[tf.float32,tf.uint8])\n",
    "    image.set_shape([IMAGE_HEIGHT,IMAGE_WIDTH,3 ])\n",
    "    mask.set_shape([IMAGE_HEIGHT,IMAGE_WIDTH,NUM_CLASSES])\n",
    "    return image,mask\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(x,y,batch=BATCH_SIZE):\n",
    "    dataset=tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    dataset=dataset.shuffle(buffer_size=5000)\n",
    "    dataset=dataset.map(preprocess)\n",
    "    dataset=dataset.batch(batch)\n",
    "    dataset=dataset.prefetch(2)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=tf_dataset(train_x,train_y,batch=BATCH_SIZE)\n",
    "valid_dataset=tf_dataset(valid_x,valid_y,batch=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[3,3,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[150], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     47\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_unet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     50\u001b[0m         loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     51\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(LR)\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     54\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m         ModelCheckpoint(model_path, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     56\u001b[0m         ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     57\u001b[0m         CSVLogger(csv_path, append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     58\u001b[0m         EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     59\u001b[0m     ]\n",
      "Cell \u001b[1;32mIn[150], line 34\u001b[0m, in \u001b[0;36mbuild_unet\u001b[1;34m(input_shape, num_classes)\u001b[0m\n\u001b[0;32m     31\u001b[0m s3, p3 \u001b[38;5;241m=\u001b[39m encoder_block(p2, \u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m     32\u001b[0m s4, p4 \u001b[38;5;241m=\u001b[39m encoder_block(p3, \u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m b1 \u001b[38;5;241m=\u001b[39m \u001b[43mconv_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m d1 \u001b[38;5;241m=\u001b[39m decoder_block(b1, s4, \u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m     37\u001b[0m d2 \u001b[38;5;241m=\u001b[39m decoder_block(d1, s3, \u001b[38;5;241m256\u001b[39m)\n",
      "Cell \u001b[1;32mIn[150], line 9\u001b[0m, in \u001b[0;36mconv_block\u001b[1;34m(input, num_filters)\u001b[0m\n\u001b[0;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m BatchNormalization()(x)\n\u001b[0;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m Activation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n\u001b[1;32m----> 9\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_filters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m BatchNormalization()(x)\n\u001b[0;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m Activation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[0;32m   2099\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[1;32m-> 2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m   2108\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m   2109\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2112\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[0;32m   2113\u001b[0m )\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[3,3,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024)\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (384, 384, 3)\n",
    "    model = build_unet(input_shape,18)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(LR)\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path, append=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "    ]\n",
    "\n",
    "    model.fit(train_dataset,\n",
    "        validation_data=valid_dataset,\n",
    "        epochs=NUM_EPOCH,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    # model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[7,7,512,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     46\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m18\u001b[39m  \u001b[38;5;66;03m# Set the number of classes for segmentation\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_vgg16_segmentation_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Print the model summary\u001b[39;00m\n\u001b[0;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[133], line 11\u001b[0m, in \u001b[0;36mbuild_vgg16_segmentation_model\u001b[1;34m(input_shape, num_classes)\u001b[0m\n\u001b[0;32m      8\u001b[0m vgg16 \u001b[38;5;241m=\u001b[39m VGG16(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Convert the fully connected layers into convolutional layers\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfc1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvgg16\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m4096\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m Conv2D(num_classes, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[0;32m   2099\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[1;32m-> 2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m   2108\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m   2109\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2112\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[0;32m   2113\u001b[0m )\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[7,7,512,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_vgg16_segmentation_model(input_shape=(384, 384, 3), num_classes=21):\n",
    "    # Load the VGG16 model without the top fully connected layers\n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Convert the fully connected layers into convolutional layers\n",
    "    x = Conv2D(4096, (7, 7), activation='relu', padding='same', name='fc1')(vgg16.output)\n",
    "    x = Conv2D(4096, (1, 1), activation='relu', padding='same', name='fc2')(x)\n",
    "    x = Conv2D(num_classes, (1, 1), activation='linear', padding='same', name='predictions')(x)\n",
    "\n",
    "    # Upsample the feature maps to match the original image size\n",
    "    x = Conv2DTranspose(num_classes, kernel_size=(4, 4), strides=(2, 2), padding='same', name='up1')(x)\n",
    "    x = Conv2DTranspose(num_classes, kernel_size=(4, 4), strides=(2, 2), padding='same', name='up2')(x)\n",
    "    x = Conv2DTranspose(num_classes, kernel_size=(16, 16), strides=(8, 8), padding='same', name='up3')(x)\n",
    "\n",
    "    # Add skip connections to fuse features from different layers\n",
    "    f1 = vgg16.get_layer('block1_conv2').output\n",
    "    f2 = vgg16.get_layer('block2_conv2').output\n",
    "    f3 = vgg16.get_layer('block3_conv3').output\n",
    "    f4 = vgg16.get_layer('block4_conv3').output\n",
    "    f5 = vgg16.get_layer('block5_conv3').output\n",
    "\n",
    "    # Upsample feature maps from each block to match the final output size\n",
    "    f2 = Conv2DTranspose(num_classes, kernel_size=(4, 4), strides=(2, 2), padding='same', name='up_f2')(f2)\n",
    "    f3 = Conv2DTranspose(num_classes, kernel_size=(8, 8), strides=(4, 4), padding='same', name='up_f3')(f3)\n",
    "    f4 = Conv2DTranspose(num_classes, kernel_size=(16, 16), strides=(8, 8), padding='same', name='up_f4')(f4)\n",
    "    f5 = Conv2DTranspose(num_classes, kernel_size=(32, 32), strides=(16, 16), padding='same', name='up_f5')(f5)\n",
    "\n",
    "    # Concatenate the upsampled feature maps\n",
    "    x = concatenate([x, f1, f2, f3, f4, f5], axis=3)\n",
    "\n",
    "    # Final upsampling to match the original image size\n",
    "    x = Conv2DTranspose(num_classes, kernel_size=(32, 32), strides=(16, 16), padding='same', name='up4')(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=vgg16.input, outputs=x)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the model\n",
    "input_shape = (384, 384, 3)\n",
    "num_classes = 18  # Set the number of classes for segmentation\n",
    "model = build_vgg16_segmentation_model(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_mask(path):\n",
    "    \n",
    "#     #use the image number to generate corropoding cmap\n",
    "#     x=np.load(\"arrfile.npy\")\n",
    "#     #coverting to jpg image for prcessingW\n",
    "#     output=[]\n",
    "#     for i,color in enumerate(COLORMAP):\n",
    "#         cmap=np.equal(x, color)\n",
    "#         cv2.imwrite(f\"test_map_{i}.jpg\", cmap*255)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts a given mask image into binary mask for all classes and save it\n",
    "\n",
    "def readMask(x):\n",
    "    #x is an np array not a mask_list object\n",
    "\n",
    "\n",
    "    \"\"\"Mask processing\"\"\"\n",
    "    output=[]\n",
    "    for  i, color in enumerate(COLOR_MAP):\n",
    "        color=np.array(color)\n",
    "        cmap=np.equal(x,color)\n",
    "        cv2.imwrite(f\"cmap_from_array_{i}.png\",cmap*255)\n",
    "        \n",
    "        \n",
    "    #     output.append(cmap)\n",
    "\n",
    "    # output=np.stack(output, axis=-1)\n",
    "    # output=output.astype(np.uint8)\n",
    "    # \"\"\"the output file has all the masked prcessed from class 1 to 17\"\"\"\n",
    "    # return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfasf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=np.array(np.array(img_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list[0].save(\"out.jpg\",\"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.PngImagePlugin.PngImageFile'>\n"
     ]
    }
   ],
   "source": [
    "im=Image.open(\"img1.png\")\n",
    "print(type(im))\n",
    "# im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image conversion process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing- fetching data using api and saving it localy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_mask_dataset(img_list,mask_list):    \n",
    "    def save_img(img_list):\n",
    "        for k in range(1000):\n",
    "            img_list[k].save(f\"D:\\\\work\\\\reserch work\\\\shivgami mam\\\\dataset\\\\train\\\\input\\\\img_{k}.jpg\",\"jpeg\")\n",
    "\n",
    "    def save_mask(mask_list):\n",
    "        for k in range(1000):\n",
    "            mask_list[k].save(f\"D:\\\\work\\\\reserch work\\\\shivgami mam\\\\dataset\\\\train\\\\Categories\\\\img_{k}.jpg\",\"jpeg\")\n",
    "\n",
    "    save_img(img_list)\n",
    "    save_mask(mask_list)         \n",
    "\n",
    "build_image_mask_dataset(img_list,mask_list)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image conversion process - end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    \"\"\"\n",
    "    x-represent the image\n",
    "    y-represent the mask\n",
    "    \"\"\"\n",
    "    def get_image_mask(x,y):\n",
    "        return readImg(x), readMask(y)\n",
    "\n",
    "    image,mask=tf.numpy_function(get_image_mask, [x,y], [tf.float32, tf.uint8])\n",
    "    image.set_shape([600,400],3)\n",
    "    mask.set_shape([600,400,18])\n",
    "    \"\"\"600*400 image size and 18 is the number of output classes\"\"\"\n",
    "    return image,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert object to 'str' for 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[85], line 9\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_image_mask\u001b[39m(x,y):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m readImg(x), readMask(y)\n\u001b[1;32m----> 9\u001b[0m image,mask\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_image_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m image\u001b[38;5;241m.\u001b[39mset_shape([\u001b[38;5;241m600\u001b[39m,\u001b[38;5;241m400\u001b[39m],\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     11\u001b[0m mask\u001b[38;5;241m.\u001b[39mset_shape([\u001b[38;5;241m600\u001b[39m,\u001b[38;5;241m400\u001b[39m,\u001b[38;5;241m18\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[85], line 7\u001b[0m, in \u001b[0;36mpreprocess.<locals>.get_image_mask\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_image_mask\u001b[39m(x,y):\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreadImg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, readMask(y)\n",
      "Cell \u001b[1;32mIn[83], line 2\u001b[0m, in \u001b[0;36mreadImg\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadImg\u001b[39m(x):\n\u001b[1;32m----> 2\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_COLOR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     x\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      4\u001b[0m     x\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't convert object to 'str' for 'filename'"
     ]
    }
   ],
   "source": [
    "preprocess(np.array(img_list[0]),np.array(mask_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset=tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    dataset=dataset.shuffle(buffer_size=5000)\n",
    "    dataset=dataset.map(preprocess)\n",
    "    dataset=dataset.batch(batch)\n",
    "    dataset=dataset.prefetch(2)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551460>) with an unsupported type (<class 'PIL.JpegImagePlugin.JpegImageFile'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:103\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    102\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    106\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:487\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[1;34m(element, use_fallback)\u001b[0m\n\u001b[0;32m    484\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[1;32m--> 487\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    488\u001b[0m     element,\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not build a `TypeSpec` for [<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551460>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551280>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551580>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551190>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551B80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551E20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551DF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551100>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5512E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551250>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5515B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551910>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5519D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551940>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551C10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551D00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B0A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B550>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B7F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62BA00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62BCA0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62BEB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B040>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B2B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B3A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B310>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B790>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B850>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B7C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62BC40>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62BC70>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF62B9A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F402280>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F402670>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F4023A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F402910>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F402B20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F402DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F402FD0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F402220>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F402310>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F4023D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F402340>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F4027C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F402880>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F4027F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F402C70>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x597 at 0x1961F402D30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F4029D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F4192E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419760>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419970>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419C10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419E20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x564 at 0x1961F419CD0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419160>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419100>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F4195E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419550>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F4199D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419A90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419A00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419E80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1961F419BE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF4E4490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF4E4070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B60A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B6520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B6250>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B67C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B69D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B61C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B6100>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B6490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B6550>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B64C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B6940>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B6BE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B6EE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B6790>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B6AF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223B6D60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CB5B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CB3A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CBFA0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CB4F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CBD90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CB7C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CB700>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CBAC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CBB80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CB370>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CBA90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CBB20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CB490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CBFD0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CD4C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CD280>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CD070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CDAF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CD400>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CD9A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CD370>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CDC10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CD9D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CDA30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CD460>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CD3A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CD8B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CDA00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CDDC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223CD520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DA070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DA1F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DA1C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DA2E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DA3D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DA4C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DA5B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DA6A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DA790>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DA880>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DA970>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DAA60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DAB50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DAC40>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DAD30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DAE20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223DAF10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E6070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E6220>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E6100>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E6310>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E6400>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E64F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E65E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E66D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=315x600 at 0x196223E67C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E68B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E69A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E6A90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E6B80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E6C70>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E6D60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E6E50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196223E6D90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58E0A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58E250>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58E130>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58E340>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58E430>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58E520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58E610>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=339x600 at 0x195FF58E700>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x581 at 0x195FF58E7F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58E8E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58E9D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58EAC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58EBB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58ECA0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58ED90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58EE80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF58EDC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5840D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584280>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584160>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584370>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584460>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584550>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584640>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584730>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584820>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584910>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584A00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584AF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584BE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584CD0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584EB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF584D00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AF1C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AF190>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AF2B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AF3A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AF490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AF580>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AF670>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AF760>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AF850>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AF940>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AFA30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AFB20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AFC10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AFD00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AFDF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF5AFEE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63E070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63E1F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63E1C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63E2E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63E3D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63E4C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63E5B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63E6A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63E790>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63E880>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63E970>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63EA60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63EB50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63EC40>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63ED30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63EE20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF63EF10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626332070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626332220>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626332100>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626332310>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626332400>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=316x600 at 0x196263324F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196263325E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196263326D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196263327C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196263328B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196263329A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626332A90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626332B80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626332C70>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626332D60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626332E50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626332D90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196263480A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348250>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348130>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348340>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348430>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348610>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348700>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196263487F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196263488E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=339x600 at 0x196263489D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348AC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348BB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348CA0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348D90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348E80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19626348DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635F0D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635F280>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635F160>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635F370>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635F460>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635F550>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635F640>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635F730>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635F820>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635F910>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635FA00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635FAF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635FBE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635FCD0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635FDC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635FEB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962635FD00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B51C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5190>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B52B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B53A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5580>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5670>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5760>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5850>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5940>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5A30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5B20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5C10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5D00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5DF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2B5EE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CA070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CA1F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CA1C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CA2E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CA3D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CA4C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CA5B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CA6A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CA790>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CA880>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CA970>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=336x509 at 0x1962A2CAA60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CAB50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CAC40>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CAD30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CAE20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2CAF10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E0070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E0220>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E0100>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E0310>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E0400>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E04F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E05E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E06D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E07C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E08B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E09A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E0A90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E0B80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E0C70>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E0D60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E0E50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962A2E0D90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D2670A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267250>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267130>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267340>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267430>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267610>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267700>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D2677F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D2678E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D2679D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=355x600 at 0x1962D267AC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267BB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267CA0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267D90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267E80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D267DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27D0D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27D280>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27D160>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27D370>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27D460>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27D550>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27D640>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27D730>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27D820>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27D910>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27DA00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27DAF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27DBE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27DCD0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27DDC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27DEB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D27DD00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D2941C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294190>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D2942B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D2943A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294580>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294670>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294760>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294850>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294940>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294A30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294B20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294C10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294D00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294DF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1962D294EE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E9070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E91F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E91C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E92E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E93D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E94C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E95B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E96A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E9790>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E9880>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E9970>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E9A60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E9B50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E9C40>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x527 at 0x196311E9D30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E9E20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311E9F10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FF070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=392x600 at 0x196311FF220>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FF1F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FF310>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FF400>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FF4F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FF5E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FF6D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FF7C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FF8B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FF9A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FFA90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FFB80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FFC70>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FFD60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FFE50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196311FFD90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196312160A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216250>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216130>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216340>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216430>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216610>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216700>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196312167F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196312168E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196312169D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216AC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216BB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216CA0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216D90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216E80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19631216DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419C0D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419C280>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419C160>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419C370>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419C460>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419C550>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419C640>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419C730>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419C820>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419C910>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419CA00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419CAF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419CBE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419CCD0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419CDC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419CEB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963419CD00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B21C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B2190>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B22B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B23A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B2490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x600 at 0x196341B2580>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B2670>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B2760>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B2850>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=336x600 at 0x196341B2940>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B2A30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B2B20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B2C10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B2D00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B2DF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341B2EE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C7070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C71F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C71C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C72E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C73D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C74C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C75B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C76A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C7790>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C7880>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C7970>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C7A60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C7B50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C7C40>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C7D30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C7E20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196341C7F10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811E070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811E220>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811E100>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811E310>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811E400>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811E4F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811E5E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811E6D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811E7C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811E8B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811E9A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811EA90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811EB80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811EC70>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811ED60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811EE50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963811ED90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196381340A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134250>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134130>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134340>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134430>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134610>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134700>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196381347F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196381348E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x196381349D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134AC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134BB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134CA0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134D90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134E80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19638134DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814A0D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814A280>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814A160>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814A370>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814A460>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814A550>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814A640>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814A730>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814A820>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814A910>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814AA00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814AAF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814ABE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814ACD0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814ADC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814AEB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963814AD00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D11C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1190>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D12B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D13A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1580>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1670>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1760>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1850>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1940>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1A30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1B20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1C10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1D00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1DF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0D1EE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E5070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E51F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E51C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E52E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E53D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x532 at 0x1963B0E54C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E55B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E56A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E5790>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E5880>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E5970>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E5A60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E5B50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E5C40>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E5D30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E5E20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0E5F10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FD070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FD220>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FD100>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FD310>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FD400>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FD4F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FD5E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FD6D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FD7C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FD8B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FD9A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FDA90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FDB80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FDC70>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FDD60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FDE50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963B0FDD90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F0530A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053250>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053130>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053340>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053430>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053610>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053700>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F0537F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F0538E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F0539D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053AC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053BB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053CA0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053D90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053E80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F053DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F0690D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069280>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069160>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069370>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069460>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069550>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069640>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069730>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069820>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069910>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069A00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069AF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069BE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069CD0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069EB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F069D00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07F1C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07F190>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07F2B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07F3A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07F490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07F580>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07F670>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07F760>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07F850>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07F940>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07FA30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07FB20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07FC10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07FD00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07FDF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1963F07FEE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD4070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD41F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD41C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD42E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD43D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD44C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD45B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD46A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD4790>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD4880>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD4970>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD4A60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD4B50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD4C40>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD4D30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD4E20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FD4F10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEB070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEB220>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEB100>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEB310>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=332x600 at 0x19642FEB400>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEB4F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEB5E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEB6D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEB7C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEB8B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEB9A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEBA90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEBB80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEBC70>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEBD60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEBE50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19642FEBD90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F710A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71250>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71130>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71340>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71430>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71610>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71700>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=333x578 at 0x19645F717F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F718E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F719D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71AC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71BB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71CA0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=291x600 at 0x19645F71D90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71E80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F71DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F880D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88280>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88160>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88370>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88460>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88550>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88640>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88730>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88820>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88910>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88A00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88AF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88BE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88CD0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88EB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F88D00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9E1C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9E190>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9E2B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9E3A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9E490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9E580>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9E670>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9E760>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9E850>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9E940>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9EA30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9EB20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9EC10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9ED00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19645F9EDF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=263x600 at 0x19645F9EEE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF2070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF21F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF21C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF22E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF23D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF24C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF25B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF26A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF2790>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF2880>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF2970>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF2A60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF2B50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF2C40>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF2D30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF2E20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649EF2F10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0A070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0A220>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0A100>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0A310>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0A400>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0A4F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0A5E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0A6D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0A7C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0A8B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0A9A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0AA90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0AB80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0AC70>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0AD60>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0AE50>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F0AD90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F200A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20250>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20130>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20340>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20430>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20520>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20610>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20700>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F207F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F208E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F209D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20AC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20BB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20CA0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20D90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20E80>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x19649F20DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA70D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7280>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7160>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7370>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7460>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7550>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7640>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7730>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7820>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7910>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7A00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7AF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7BE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=332x579 at 0x1964CEA7CD0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7DC0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7EB0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEA7D00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBD1C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBD190>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBD2B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBD3A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBD490>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBD580>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBD670>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBD760>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBD850>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBD940>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBDA30>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBDB20>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBDC10>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBDD00>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBDDF0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CEBDEE0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CED1070>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CED11F0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CED11C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CED12E0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CED13D0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CED14C0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CED15B0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CED16A0>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CED1790>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CED1880>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x1964CED1970>] with type list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"dataset pipeline\"\"\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mtf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m test_dataset\u001b[38;5;241m=\u001b[39mtf_dataset(test_x,test_y,batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[1;32mIn[86], line 2\u001b[0m, in \u001b[0;36mtf_dataset\u001b[1;34m(x, y, batch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtf_dataset\u001b[39m(x, y, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     dataset\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m      4\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mmap(preprocess)\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:814\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    738\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4708\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m   4706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   4707\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4708\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4709\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m   4710\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:108\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    103\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    106\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 108\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensorSpec):\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1629\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[0;32m   1631\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1634\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1635\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m   1637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1638\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1641\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    341\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    342\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[1;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x600 at 0x195FF551460>) with an unsupported type (<class 'PIL.JpegImagePlugin.JpegImageFile'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "\"\"\"dataset pipeline\"\"\"\n",
    "train_dataset=tf_dataset(train_x,train_y,batch=4)\n",
    "test_dataset=tf_dataset(test_x,test_y,batch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempimg=np.array(mask_list[0],dtype=np.float32)\n",
    "readMask(tempimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.array(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(tempimg,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "11\n",
      "7\n",
      "15\n",
      "14\n",
      "8\n",
      "16\n",
      "13\n",
      "12\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trash code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fcn_vgg16(input_shape):\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    \n",
    "    # Taking only the convolutional part of VGG16\n",
    "    conv_layers = vgg16.get_layer('block5_conv3').output\n",
    "    \n",
    "    # Adding fully convolutional layers\n",
    "    conv6 = Conv2D(4096, (7, 7), activation='relu', padding='same', name='conv6')(conv_layers)\n",
    "    conv7 = Conv2D(4096, (1, 1), activation='relu', padding='same', name='conv7')(conv6)\n",
    "    conv8 = Conv2D(18, (1, 1), activation='softmax', padding='same', name='conv8')(conv7)\n",
    "    \n",
    "    # Upsampling\n",
    "    upsampled = UpSampling2D(size=(32, 32), interpolation='bilinear')(conv8)\n",
    "    \n",
    "    model = Model(inputs=vgg16.input, outputs=upsampled)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_phpc(input_shape):\n",
    "    # Image-level parsing network\n",
    "    image_level_model = build_fcn_vgg16(input_shape)\n",
    "    \n",
    "    # Head-parsing sub-network\n",
    "    head_input = tf.keras.layers.Input(shape=(input_shape[0]*2, input_shape[1]*2, input_shape[2]))\n",
    "    head_model = build_fcn_vgg16((input_shape[0]*2, input_shape[1]*2, input_shape[2]))\n",
    "    \n",
    "    # Body-parsing sub-network\n",
    "    body_input = tf.keras.layers.Input(shape=(input_shape[0]*2, input_shape[1]*2, input_shape[2]))\n",
    "    body_model = build_fcn_vgg16((input_shape[0]*2, input_shape[1]*2, input_shape[2]))\n",
    "    \n",
    "    # Combining all the networks\n",
    "    combined = Concatenate()([image_level_model.output, head_model.output, body_model.output])\n",
    "    final_output = Conv2D(18, (1, 1), activation='softmax', padding='same')(combined)\n",
    "    \n",
    "    model = Model(inputs=[image_level_model.input, head_input, body_input], outputs=final_output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_phpc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# model.summary()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[54], line 11\u001b[0m, in \u001b[0;36mbuild_phpc\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Body-parsing sub-network\u001b[39;00m\n\u001b[0;32m     10\u001b[0m body_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(input_shape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, input_shape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, input_shape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m---> 11\u001b[0m body_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_fcn_vgg16\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Combining all the networks\u001b[39;00m\n\u001b[0;32m     14\u001b[0m combined \u001b[38;5;241m=\u001b[39m Concatenate()([image_level_model\u001b[38;5;241m.\u001b[39moutput, head_model\u001b[38;5;241m.\u001b[39moutput, body_model\u001b[38;5;241m.\u001b[39moutput])\n",
      "Cell \u001b[1;32mIn[53], line 8\u001b[0m, in \u001b[0;36mbuild_fcn_vgg16\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m      5\u001b[0m conv_layers \u001b[38;5;241m=\u001b[39m vgg16\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock5_conv3\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moutput\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Adding fully convolutional layers\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m conv6 \u001b[38;5;241m=\u001b[39m \u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconv6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m conv7 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m4096\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv7\u001b[39m\u001b[38;5;124m'\u001b[39m)(conv6)\n\u001b[0;32m     10\u001b[0m conv8 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m18\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv8\u001b[39m\u001b[38;5;124m'\u001b[39m)(conv7)\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[0;32m   2099\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[1;32m-> 2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m   2108\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m   2109\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2112\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[0;32m   2113\u001b[0m )\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = (384, 384, 3)\n",
    "model = build_phpc(input_shape)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024)\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (384, 384, 3)\n",
    "    model = build_unet(input_shape,18)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(LR)\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path, append=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "    ]\n",
    "\n",
    "    model.fit(train_dataset,\n",
    "        validation_data=valid_dataset,\n",
    "        epochs=NUM_EPOCH,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    # model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
